{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4Mr5_uScoeIN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Fabrice\\anaconda3\\envs\\decrypto\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from english_words import get_english_words_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "X7ptNjicmiXL"
   },
   "outputs": [],
   "source": [
    "def download_and_extract_glove(dim=50, out_folder='.', force=False):\n",
    "    \"\"\"\n",
    "    Download the 'glove.6B.zip' file (if needed) from Stanford NLP\n",
    "    and extract only the glove.6B.{dim}d.txt file.\n",
    "\n",
    "    :param dim: Dimension of the GloVe vectors (50, 100, 200, or 300).\n",
    "    :param out_folder: Folder in which the .txt file will be placed.\n",
    "    :param force: If True, re-download and re-extract even if the file exists.\n",
    "    :return: Full path to the extracted GloVe file (e.g., './glove.6B.50d.txt').\n",
    "    \"\"\"\n",
    "    glove_zip_filename = 'glove.6B.zip'\n",
    "    glove_zip_filepath = os.path.join(out_folder, glove_zip_filename)\n",
    "    glove_filename = f'glove.6B.{dim}d.txt'\n",
    "    glove_filepath = os.path.join(out_folder, glove_filename)\n",
    "\n",
    "    # 1) If file already exists (and not force), just return it\n",
    "    if os.path.isfile(glove_filepath) and not force:\n",
    "        print(f\"[download_and_extract_glove] Found existing file: {glove_filepath}\")\n",
    "        return glove_filepath\n",
    "\n",
    "    # 2) Ensure out_folder exists\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    # 3) If GloVe zip not present (or force), download it\n",
    "    if not os.path.isfile(glove_zip_filepath) or force:\n",
    "        url = 'http://nlp.stanford.edu/data/glove.6B.zip'\n",
    "        print(f\"[download_and_extract_glove] Downloading GloVe.6B.zip to {glove_zip_filepath}...\")\n",
    "        response = requests.get(url, stream=True)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        with open(glove_zip_filepath, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        print(\"[download_and_extract_glove] Download complete.\")\n",
    "\n",
    "    # 4) Extract only the needed dimension file if it doesn't exist or force\n",
    "    with zipfile.ZipFile(glove_zip_filepath, 'r') as zf:\n",
    "        if glove_filename not in zf.namelist():\n",
    "            raise ValueError(f\"[download_and_extract_glove] {glove_filename} not found in zip!\")\n",
    "        print(f\"[download_and_extract_glove] Extracting {glove_filename} to {out_folder}...\")\n",
    "        zf.extract(glove_filename, path=out_folder)\n",
    "\n",
    "    print(f\"[download_and_extract_glove] GloVe file ready at: {glove_filepath}\")\n",
    "    return glove_filepath\n",
    "\n",
    "def load_words_with_pandas(file_path):\n",
    "    \"\"\"\n",
    "    Load words from a text file (one per line) using pandas.\n",
    "    \n",
    "    :param file_path: Path to the text file\n",
    "    :return: A list of strings (words), skipping empty lines\n",
    "    \"\"\"\n",
    "    # Read the file as a single-column CSV where each line = one row\n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        header=None,         # no header row in the file\n",
    "        names=[\"word\"],      # name the single column 'word'\n",
    "        dtype=str,\n",
    "        encoding='utf-8',\n",
    "        engine='python'      # often needed when sep='\\n'\n",
    "    )\n",
    "    \n",
    "    # Convert the column to a list, dropping any NaN or empty strings\n",
    "    words = df[\"word\"].dropna().tolist()\n",
    "    \n",
    "    # Strip whitespace and remove any truly empty lines\n",
    "    words = [w.strip() for w in words if w.strip()]\n",
    "    \n",
    "    return words\n",
    "\n",
    "\n",
    "class DecryptoClueRecommender:\n",
    "    \"\"\"\n",
    "    A class to recommend Decrypto clues using:\n",
    "      - A perplexity matrix M_p (via GPT-2)\n",
    "      - A similarity matrix M_s (via GloVe embeddings)\n",
    "      - A vocabulary of ~1000 words\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, vocab_list, glove_path,\n",
    "                 matrix_dir='matrices',\n",
    "                 matrix_prefix='decrypto',\n",
    "                 force_matrix_build=False):\n",
    "        \"\"\"\n",
    "        Initialize with a given vocabulary list of words and path to a GloVe file.\n",
    "        Also specify paths/prefixes for saving/loading M_p and M_s.\n",
    "\n",
    "        :param vocab_list: list of strings (our vocabulary)\n",
    "        :param glove_path: file path to GloVe embeddings (e.g., \"glove.6B.50d.txt\")\n",
    "        :param matrix_dir: folder where M_p.npy and M_s.npy will be saved/loaded\n",
    "        :param matrix_prefix: prefix to use for matrix files (e.g., \"decrypto\")\n",
    "        :param force_matrix_build: if True, rebuild matrices even if they exist\n",
    "        \"\"\"\n",
    "        self.vocab = vocab_list\n",
    "        self.word_to_idx = {word: i for i, word in enumerate(self.vocab)}\n",
    "        self.N = len(self.vocab)\n",
    "\n",
    "        # Decide which device we're using (GPU if available)\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # LLM & tokenizer for perplexity\n",
    "        self.model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "\n",
    "\n",
    "        # Setup matrix paths\n",
    "        self.matrix_dir = matrix_dir\n",
    "        os.makedirs(self.matrix_dir, exist_ok=True)\n",
    "        self.matrix_prefix = matrix_prefix\n",
    "        self.m_p_path = os.path.join(self.matrix_dir, f\"{self.matrix_prefix}_Mp.npy\")\n",
    "        self.m_s_path = os.path.join(self.matrix_dir, f\"{self.matrix_prefix}_Ms.npy\")\n",
    "\n",
    "        # Prepare placeholders for the two matrices\n",
    "        self.M_p = None  # Perplexity matrix\n",
    "        self.M_s = None  # Similarity matrix\n",
    "\n",
    "        # Optionally load from disk if they exist\n",
    "        if not force_matrix_build:\n",
    "            self._try_load_matrices()\n",
    "        \n",
    "        if not os.path.exists(self.m_p_path):\n",
    "            print(f\"[DecryptoClueRecommender] Initializing {self.model_name}...\")\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(self.model_name).to(self.device)\n",
    "            self.model.eval()  # put in eval mode\n",
    "            \n",
    "        if not os.path.exists(self.m_s_path):\n",
    "            # Load GloVe embeddings\n",
    "            self.embeddings = self._load_glove_embeddings(glove_path)\n",
    "\n",
    "    def _try_load_matrices(self):\n",
    "        \"\"\"\n",
    "        Attempt to load M_p and M_s from self.m_p_path and self.m_s_path.\n",
    "        If they exist and match the correct shape, set them.\n",
    "        \"\"\"\n",
    "        loaded = False\n",
    "        if os.path.isfile(self.m_p_path) and os.path.isfile(self.m_s_path):\n",
    "            # Check shapes to ensure it matches our current vocabulary\n",
    "            M_p_temp = np.load(self.m_p_path)\n",
    "            M_s_temp = np.load(self.m_s_path)\n",
    "            if M_p_temp.shape == (self.N, self.N) and M_s_temp.shape == (self.N, self.N):\n",
    "                self.M_p = M_p_temp\n",
    "                self.M_s = M_s_temp\n",
    "                loaded = True\n",
    "                print(f\"[DecryptoClueRecommender] Loaded matrices from disk:\\n\"\n",
    "                      f\"  M_p: {self.m_p_path}\\n\"\n",
    "                      f\"  M_s: {self.m_s_path}\")\n",
    "\n",
    "        if not loaded:\n",
    "            print(\"[DecryptoClueRecommender] No valid saved matrices found. Call build_matrices().\")\n",
    "\n",
    "    def _load_glove_embeddings(self, glove_file):\n",
    "        \"\"\"\n",
    "        Load GloVe embeddings from a local file into a dict: {word: np.array([...])}\n",
    "        \"\"\"\n",
    "        if not os.path.isfile(glove_file):\n",
    "            raise FileNotFoundError(f\"[DecryptoClueRecommender] GloVe file not found: {glove_file}\")\n",
    "\n",
    "        print(f\"[DecryptoClueRecommender] Loading GloVe embeddings from {glove_file}...\")\n",
    "\n",
    "        embeddings_dict = {}\n",
    "        dim = None\n",
    "        with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                values = line.strip().split()\n",
    "                word = values[0]\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "                if dim is None:\n",
    "                    dim = len(coefs)\n",
    "                if len(coefs) == dim:\n",
    "                    embeddings_dict[word] = coefs\n",
    "        print(f\"[DecryptoClueRecommender] Loaded {len(embeddings_dict)} word vectors (dim={dim}).\")\n",
    "        return embeddings_dict\n",
    "\n",
    "    def _get_glove_vector(self, word):\n",
    "        \"\"\"\n",
    "        Retrieve the GloVe vector for the given word.\n",
    "        If the word isn't in GloVe, return a zero vector.\n",
    "        \"\"\"\n",
    "        # GloVe is mostly lowercase; might need to lower() your words for best coverage\n",
    "        lookup_word = word.lower()\n",
    "        if lookup_word in self.embeddings:\n",
    "            return self.embeddings[lookup_word]\n",
    "        else:\n",
    "            dim = next(iter(self.embeddings.values())).shape[0]\n",
    "            return np.zeros(dim, dtype='float32')\n",
    "\n",
    "    def _cosine_similarity(self, v1, v2):\n",
    "        \"\"\"\n",
    "        Compute cosine similarity between two vectors.\n",
    "        \"\"\"\n",
    "        norm1 = np.linalg.norm(v1)\n",
    "        norm2 = np.linalg.norm(v2)\n",
    "        if norm1 == 0 or norm2 == 0:\n",
    "            return 0.0\n",
    "        return float(np.dot(v1, v2) / (norm1 * norm2))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _get_perplexity(self, prompt):\n",
    "        \"\"\"\n",
    "        Approximate perplexity of a prompt using self.model_name.\n",
    "        We'll do a direct calculation on the entire prompt.\n",
    "        \"\"\"\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
    "        outputs = self.model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        return float(torch.exp(loss))\n",
    "\n",
    "    def build_matrices(self, save_to_disk=True):\n",
    "        \"\"\"\n",
    "        Build M_p (perplexity) and M_s (similarity) for all pairs in vocab.\n",
    "        M_p[i, j] = perplexity of \"vocab[i]\" as a clue for \"vocab[j]\"\n",
    "        M_s[i, j] = GloVe cosine similarity between vocab[i] and vocab[j]\n",
    "\n",
    "        :param save_to_disk: if True, save M_p and M_s to .npy files after building\n",
    "        \"\"\"\n",
    "        self.M_p = np.zeros((self.N, self.N), dtype=np.float32)\n",
    "        self.M_s = np.zeros((self.N, self.N), dtype=np.float32)\n",
    "\n",
    "        print(\"[DecryptoClueRecommender] Building similarity matrix M_s (GloVe)...\")\n",
    "        # Outer loop with a progress bar\n",
    "        for i in tqdm(range(self.N), desc=\"Building M_s\"):\n",
    "            vec_i = self._get_glove_vector(self.vocab[i])\n",
    "            for j in range(self.N):\n",
    "                if i == j:\n",
    "                    self.M_s[i, j] = 1.0\n",
    "                else:\n",
    "                    vec_j = self._get_glove_vector(self.vocab[j])\n",
    "                    self.M_s[i, j] = self._cosine_similarity(vec_i, vec_j)\n",
    "\n",
    "        # Optionally save matrices\n",
    "        if save_to_disk:\n",
    "            np.save(self.m_s_path, self.M_s)\n",
    "            print(f\"[DecryptoClueRecommender] Saved M_s to {self.m_s_path}\")\n",
    "\n",
    "        print(f\"[DecryptoClueRecommender] Building perplexity matrix M_p ({self.model_name})...\")\n",
    "        # Another progress bar for perplexity\n",
    "        for i in tqdm(range(self.N), desc=\"Building M_p\"):\n",
    "            for j in range(self.N):\n",
    "                if i == j:\n",
    "                    self.M_p[i, j] = 9999.0\n",
    "                    continue\n",
    "                clue_word = self.vocab[i]\n",
    "                keyword_word = self.vocab[j]\n",
    "                prompt_text = f\"Clue for '{keyword_word}': {clue_word}\"\n",
    "                perp = self._get_perplexity(prompt_text)\n",
    "                self.M_p[i, j] = perp\n",
    "\n",
    "        # Optionally save matrices\n",
    "        if save_to_disk:\n",
    "            np.save(self.m_p_path, self.M_p)\n",
    "            print(f\"[DecryptoClueRecommender] Saved M_p to {self.m_p_path}\")\n",
    "\n",
    "    def _objective(self, c_idx, w1_idx, w2_idx, w3_idx, w4_idx, C_prev_indices,\n",
    "                   alpha=1.0, beta=0.5, gamma=0.5):\n",
    "        \"\"\"\n",
    "        O(c, w1) = -alpha * M_p[c, w1]\n",
    "                   + beta * (M_s[c, w2] + M_s[c, w3] + M_s[c, w4])\n",
    "                   - gamma * avg_{c' in C_prev} M_s[c, c']\n",
    "        \"\"\"\n",
    "        # (A) Encourage low perplexity for (c, w1)\n",
    "        term_a = -alpha * self.M_p[c_idx, w1_idx]\n",
    "\n",
    "        # (B) Encourage ambiguity (similar to w2, w3, w4)\n",
    "        term_b = beta * (\n",
    "            self.M_s[c_idx, w2_idx] +\n",
    "            self.M_s[c_idx, w3_idx] +\n",
    "            self.M_s[c_idx, w4_idx]\n",
    "        )\n",
    "\n",
    "        # (C) Dissuade re-using the same domain as previous clues\n",
    "        if len(C_prev_indices) > 0:\n",
    "            sim_sum = sum(self.M_s[c_idx, prev_idx] for prev_idx in C_prev_indices)\n",
    "            avg_sim = sim_sum / len(C_prev_indices)\n",
    "        else:\n",
    "            avg_sim = 0.0\n",
    "        term_c = -gamma * avg_sim\n",
    "\n",
    "        return term_a + term_b + term_c\n",
    "\n",
    "    def suggest_clues(self,\n",
    "                      w1, w2, w3, w4,\n",
    "                      C_prev=None,\n",
    "                      top_k=5,\n",
    "                      alpha=1.0, beta=0.5, gamma=0.5):\n",
    "        \"\"\"\n",
    "        Suggest top-K clues for the primary keyword w1, given the other\n",
    "        3 secret words (w2, w3, w4) and a list of previously used clues.\n",
    "        Returns a list of (clue_word, score).\n",
    "        \"\"\"\n",
    "        if self.M_p is None or self.M_s is None:\n",
    "            raise ValueError(\"Matrices not built yet! Call build_matrices() or load them from disk.\")\n",
    "\n",
    "        # Convert to indices\n",
    "        try:\n",
    "            w1_idx = self.word_to_idx[w1]\n",
    "            w2_idx = self.word_to_idx[w2]\n",
    "            w3_idx = self.word_to_idx[w3]\n",
    "            w4_idx = self.word_to_idx[w4]\n",
    "        except KeyError as e:\n",
    "            raise ValueError(f\"Keyword {e} not found in vocab!\") from e\n",
    "\n",
    "        if C_prev is None:\n",
    "            C_prev = []\n",
    "        C_prev_indices = []\n",
    "        for clue_word in C_prev:\n",
    "            if clue_word in self.word_to_idx:\n",
    "                C_prev_indices.append(self.word_to_idx[clue_word])\n",
    "\n",
    "        # Compute score for each word in the vocab\n",
    "        scored_clues = []\n",
    "        for c_idx, c_word in enumerate(self.vocab):\n",
    "            # skip if it's the same as the main keyword\n",
    "            if c_idx == w1_idx:\n",
    "                continue\n",
    "\n",
    "            score = self._objective(\n",
    "                c_idx, w1_idx, w2_idx, w3_idx, w4_idx,\n",
    "                C_prev_indices,\n",
    "                alpha=alpha, beta=beta, gamma=gamma\n",
    "            )\n",
    "            scored_clues.append((c_word, score))\n",
    "\n",
    "        # Sort by descending score and take top_k\n",
    "        scored_clues.sort(key=lambda x: x[1], reverse=True)\n",
    "        return scored_clues[:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4habOnxiqQZ2",
    "outputId": "bc7781b5-9539-4af5-8416-b0fa11c9ab39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[download_and_extract_glove] Found existing file: .\\glove.6B.50d.txt\n",
      "[DecryptoClueRecommender] Loaded matrices from disk:\n",
      "  M_p: matrices\\decrypto_Mp.npy\n",
      "  M_s: matrices\\decrypto_Ms.npy\n",
      "[Main] Matrices were loaded from disk—no need to rebuild.\n",
      "\n",
      "Top clue suggestions for 'school' with keywords 'enemy', 'dream', 'story':\n",
      "  - don't (score=-155.634)\n",
      "  - a (score=-162.792)\n",
      "  - syllable (score=-173.336)\n",
      "  - noun (score=-174.747)\n",
      "  - I (score=-183.284)\n"
     ]
    }
   ],
   "source": [
    "# 1) Download or re-use GloVe (50d) if it already exists\n",
    "glove_50d_path = download_and_extract_glove(dim=50, out_folder='.', force=False)\n",
    "\n",
    "# 2) Example small vocabulary\n",
    "keywords = [\"school\", \"enemy\", \"dream\", \"story\"]\n",
    "vocab = load_words_with_pandas(\"./cew.txt\")\n",
    "\n",
    "# 3) Create the recommender with optional matrix saving/loading\n",
    "#    - matrix_dir: Where to save/load .npy files\n",
    "#    - matrix_prefix: Suffix for filenames, e.g. \"decrypto_Mp.npy\" and \"decrypto_Ms.npy\"\n",
    "#    - force_matrix_build=False => If matrices exist and match shape, they'll be loaded\n",
    "recommender = DecryptoClueRecommender(\n",
    "    vocab_list=vocab,\n",
    "    glove_path=glove_50d_path,\n",
    "    matrix_dir='matrices',\n",
    "    matrix_prefix='decrypto',\n",
    "    force_matrix_build=False  # set True to force rebuild\n",
    ")\n",
    "\n",
    "# 4) If matrices weren't already loaded, build them (and save to disk)\n",
    "if recommender.M_p is None or recommender.M_s is None:\n",
    "    print(\"[Main] Matrices not loaded from disk; building now...\")\n",
    "    recommender.build_matrices(save_to_disk=True)\n",
    "else:\n",
    "    print(\"[Main] Matrices were loaded from disk—no need to rebuild.\")\n",
    "\n",
    "# 5) Define our 4 secret words\n",
    "w1, w2, w3, w4 = keywords\n",
    "\n",
    "# Suppose we've used these clues for \"school\" before\n",
    "prev_clues_for_school = [\"fish\", \"teach\"]\n",
    "\n",
    "# 6) Generate top 5 suggestions\n",
    "suggestions = recommender.suggest_clues(\n",
    "    w1, w2, w3, w4,\n",
    "    C_prev=prev_clues_for_school,\n",
    "    top_k=5,\n",
    "    alpha=0.33,     # perplexity weight\n",
    "    beta=0.33,      # similarity-to-other-keywords weight\n",
    "    gamma=0.33      # difference-from-previous-clues weight\n",
    ")\n",
    "\n",
    "print(f\"\\nTop clue suggestions for '{w1}' with keywords '{w2}', '{w3}', '{w4}':\")\n",
    "for clue_word, score in suggestions:\n",
    "    print(f\"  - {clue_word} (score={score:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "decrypto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
